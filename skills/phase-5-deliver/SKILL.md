---
name: phase-5-deliver
description: Two-stage code review, quality gates, and automated delivery (commit + PR)
allowed-tools: [Read, Write, Bash, Grep, Glob]
user-invocable: false
---

# Phase 5: Deliver

## Overview | æ¦‚è¿°

Run final quality gates, perform two-stage code review (spec compliance + code quality), create commits, and generate pull requests for completed work.

è¿è¡Œæœ€ç»ˆè´¨é‡æ£€æŸ¥ï¼Œæ‰§è¡Œä¸¤é˜¶æ®µä»£ç å®¡æŸ¥ï¼ˆè§„èŒƒåˆè§„æ€§ + ä»£ç è´¨é‡ï¼‰ï¼Œåˆ›å»º commit å¹¶ä¸ºå®Œæˆçš„å·¥ä½œç”Ÿæˆ pull requestã€‚

## When to Use | ä½•æ—¶ä½¿ç”¨

Invoked by autopilot-orchestrator as Phase 5, after Phase 3 (Implement) completes all tasks.

## Input | è¾“å…¥

- Completed tasks from Phase 3
- Task directory: `workspace/ai/tasks/`
- Implementation files: All modified/created files

## Execution | æ‰§è¡Œ

### Step 1: Gather Implementation Summary

```bash
echo "ğŸ“Š Gathering implementation summary..."
echo ""

# Get all completed tasks
COMPLETED_TASKS=$(autopilot-cli tasks list --status passing --json)
TASK_COUNT=$(echo "$COMPLETED_TASKS" | jq 'length')

echo "âœ… Completed Tasks: $TASK_COUNT"
echo ""

# List task IDs and descriptions
echo "$COMPLETED_TASKS" | jq -r '.[] | "  â€¢ \(.id) - \(.description)"'
echo ""
```

### Step 2: Run Quality Gates

```bash
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ” Running Quality Gates..."
echo ""
echo "## VERIFICATION PRINCIPLE: Evidence Before Claims"
echo ""
echo "Every quality gate shows FULL COMMAND OUTPUT."
echo "No assertions without evidence in same message."
echo ""

# Quality Gate 1: Type Checking
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "1ï¸âƒ£  Type Checking"
echo ""
echo "Running: npx tsc --noEmit"
echo ""

TYPE_CHECK_RESULT=$(run_typecheck 2>&1)
TYPE_CHECK_STATUS=$?

echo "$TYPE_CHECK_RESULT"
echo ""
echo "Exit code: $TYPE_CHECK_STATUS"
echo ""

if [ $TYPE_CHECK_STATUS -eq 0 ]; then
  echo "âœ… VERIFIED: No type errors (see output above)"
else
  echo "âŒ VERIFIED: Type errors found (see output above)"
  GATE_FAILED=true
fi
echo ""

# Quality Gate 2: Linting
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "2ï¸âƒ£  Linting"
echo ""
echo "Running: npm run lint"
echo ""

LINT_RESULT=$(run_lint 2>&1)
LINT_STATUS=$?

echo "$LINT_RESULT"
echo ""
echo "Exit code: $LINT_STATUS"
echo ""

if [ $LINT_STATUS -eq 0 ]; then
  echo "âœ… VERIFIED: No linting errors (see output above)"
else
  echo "âŒ VERIFIED: Linting errors found (see output above)"
  GATE_FAILED=true
fi
echo ""

# Quality Gate 3: Tests
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "3ï¸âƒ£  Running All Tests"
echo ""
echo "Running: npm test"
echo ""

TEST_RESULT=$(run_all_tests 2>&1)
TEST_STATUS=$?

echo "$TEST_RESULT"
echo ""
echo "Exit code: $TEST_STATUS"
echo ""

if [ $TEST_STATUS -eq 0 ]; then
  # Extract test stats from actual output
  TEST_COUNT=$(extract_test_count "$TEST_RESULT")
  echo "âœ… VERIFIED: All tests passed (see full output above)"
  echo "   Test count: $TEST_COUNT"
else
  echo "âŒ VERIFIED: Tests failed (see failures above)"
  GATE_FAILED=true
fi
echo ""

# Quality Gate 4: Build
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "4ï¸âƒ£  Building Project"
echo ""
echo "Running: npm run build"
echo ""

BUILD_RESULT=$(run_build 2>&1)
BUILD_STATUS=$?

echo "$BUILD_RESULT"
echo ""
echo "Exit code: $BUILD_STATUS"
echo ""

if [ $BUILD_STATUS -eq 0 ]; then
  echo "âœ… VERIFIED: Build successful (see output above)"
else
  echo "âŒ VERIFIED: Build failed (see errors above)"
  GATE_FAILED=true
fi
echo ""

# Check if any gate failed
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
if [ "$GATE_FAILED" = true ]; then
  echo "âŒ Quality gates failed. Cannot proceed to delivery."
  echo ""
  echo "Review the FULL OUTPUT above for each failed gate."
  echo "Fix issues and re-run Phase 5."
  echo ""
  return 1
fi

echo "âœ… All quality gates passed!"
echo ""
echo "Evidence verified above for all 4 gates:"
echo "  â€¢ Type checking: Full tsc output shown âœ“"
echo "  â€¢ Linting: Full lint output shown âœ“"
echo "  â€¢ Tests: Full test output shown âœ“"
echo "  â€¢ Build: Full build output shown âœ“"
echo ""
```

### Step 3: Two-Stage Code Review

```bash
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ‘€ Performing Two-Stage Code Review..."
echo ""

# Stage 1: Spec Compliance Check
echo "ğŸ“‹ Stage 1: Spec Compliance Check"
echo "   (Verifying implementation meets acceptance criteria)"
echo ""

SPEC_REVIEW_RESULT=$(perform_spec_compliance_check "$COMPLETED_TASKS")
SPEC_REVIEW_STATUS=$?

if [ $SPEC_REVIEW_STATUS -eq 0 ]; then
  echo "   âœ… All acceptance criteria satisfied"
else
  echo "   âš ï¸  Spec compliance issues found:"
  echo "$SPEC_REVIEW_RESULT"
  echo ""
  echo "   Continue to Stage 2 for code quality check..."
fi
echo ""

# Stage 2: Code Quality Check
echo "ğŸ¯ Stage 2: Code Quality Check"
echo "   (Reviewing code style, patterns, and best practices)"
echo ""

QUALITY_REVIEW_RESULT=$(perform_code_quality_check)
QUALITY_REVIEW_STATUS=$?

if [ $QUALITY_REVIEW_STATUS -eq 0 ]; then
  echo "   âœ… Code quality meets standards"
else
  echo "   âš ï¸  Code quality suggestions:"
  echo "$QUALITY_REVIEW_RESULT"
  echo ""
  echo "   Note: Suggestions are advisory, not blocking"
fi
echo ""

echo "âœ… Two-stage review complete!"
echo ""
```

### Step 4: Create Git Commit with Detailed Message

```bash
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ’¾ Creating Git Commit..."
echo ""

# Get list of modified/new files
git status --short

# Generate detailed commit message with task info
COMMIT_MSG=$(generate_detailed_commit_message "$COMPLETED_TASKS")

echo "Commit message:"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
echo "$COMMIT_MSG"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
echo ""

# Stage all changes
git add .

# Create commit with detailed message and co-author
git commit -m "$(cat <<EOF
$COMMIT_MSG

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>
EOF
)"

COMMIT_STATUS=$?

if [ $COMMIT_STATUS -eq 0 ]; then
  COMMIT_SHA=$(git rev-parse --short HEAD)
  echo "âœ… Commit created: $COMMIT_SHA"
  echo ""

  # Update minimal progress file
  update_progress_txt "$COMPLETED_TASKS" "$COMMIT_SHA"
else
  echo "âŒ Commit failed"
  return 1
fi
echo ""
```

### Step 5: Create Pull Request (Optional)

```bash
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ”€ Creating Pull Request..."
echo ""

# Check if gh CLI is available
if ! command -v gh &> /dev/null; then
  echo "âš ï¸  GitHub CLI (gh) not found. Skipping PR creation."
  echo "   Install gh: https://cli.github.com/"
  echo ""
  echo "   Manual PR creation:"
  echo "   1. Push branch: git push origin $(git branch --show-current)"
  echo "   2. Create PR on GitHub"
  echo ""
else
  # Check if we're on a feature branch
  CURRENT_BRANCH=$(git branch --show-current)
  MAIN_BRANCH=$(git symbolic-ref refs/remotes/origin/HEAD | sed 's@^refs/remotes/origin/@@')

  if [ "$CURRENT_BRANCH" = "$MAIN_BRANCH" ]; then
    echo "âš ï¸  Currently on main branch ($MAIN_BRANCH)"
    echo "   Create feature branch first:"
    echo "   git checkout -b feature/autopilot-implementation"
    echo ""
  else
    # Generate PR description
    PR_TITLE=$(generate_pr_title "$COMPLETED_TASKS")
    PR_BODY=$(generate_pr_body "$COMPLETED_TASKS" "$SPEC_REVIEW_RESULT" "$QUALITY_REVIEW_RESULT")

    echo "PR Title: $PR_TITLE"
    echo ""
    echo "PR Body:"
    echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    echo "$PR_BODY"
    echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    echo ""

    # Push branch
    git push -u origin "$CURRENT_BRANCH"

    # Create PR
    gh pr create \
      --title "$PR_TITLE" \
      --body "$PR_BODY" \
      --base "$MAIN_BRANCH"

    PR_STATUS=$?

    if [ $PR_STATUS -eq 0 ]; then
      PR_URL=$(gh pr view --json url -q .url)
      echo "âœ… Pull Request created: $PR_URL"
    else
      echo "âŒ PR creation failed"
    fi
  fi
fi
echo ""
```

### Step 6: Final Summary

```bash
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ¯ Delivery Complete!"
echo ""
echo "ğŸ“Š Summary:"
echo "   Tasks completed: $TASK_COUNT"
echo "   Commit: $COMMIT_SHA"
[ -n "$PR_URL" ] && echo "   Pull Request: $PR_URL"
echo ""

echo "âœ… Quality Gates:"
echo "   â€¢ Type checking: âœ“"
echo "   â€¢ Linting: âœ“"
echo "   â€¢ Tests: âœ“ ($TEST_COUNT tests)"
echo "   â€¢ Build: âœ“"
echo ""

echo "ğŸ‘€ Code Review:"
echo "   â€¢ Spec compliance: $([ $SPEC_REVIEW_STATUS -eq 0 ] && echo 'âœ“' || echo 'âš ï¸  with notes')"
echo "   â€¢ Code quality: $([ $QUALITY_REVIEW_STATUS -eq 0 ] && echo 'âœ“' || echo 'âš ï¸  with suggestions')"
echo ""

echo "ğŸ‰ Autopilot workflow complete!"
echo ""
```

### Step 7: Update State

```bash
# Update state to complete
autopilot-cli state update --phase complete
```

### Step 8: Return Result

```yaml
---PHASE RESULT---
phase: deliver
status: complete
tasks_delivered: {N}
commit_sha: {sha}
pr_url: {url}
quality_gates:
  typecheck: passed
  lint: passed
  tests: passed ({N} tests)
  build: passed
code_review:
  spec_compliance: $([ $SPEC_REVIEW_STATUS -eq 0 ] && echo 'passed' || echo 'passed_with_notes')
  code_quality: $([ $QUALITY_REVIEW_STATUS -eq 0 ] && echo 'passed' || echo 'passed_with_suggestions')
next_phase: null
summary: |\
  Delivered {N} tasks successfully.
  All quality gates passed.
  Code review complete.
  Commit created and PR submitted.
  Ready for human review and merge.
---END PHASE RESULT---
```

## Helper Functions | è¾…åŠ©å‡½æ•°

### Run Type Check

```bash
run_typecheck() {
  # Detect project type and run appropriate type checker
  if [ -f "tsconfig.json" ]; then
    npx tsc --noEmit 2>&1
  elif [ -f "pyproject.toml" ] || [ -f "setup.py" ]; then
    mypy . 2>&1 || echo "mypy not configured, skipping"
  elif [ -f "go.mod" ]; then
    go vet ./... 2>&1
  else
    echo "No type checking available for this project"
    return 0
  fi
}
```

### Run Lint

```bash
run_lint() {
  # Detect project type and run appropriate linter
  if [ -f "package.json" ]; then
    npm run lint 2>&1 || npx eslint . 2>&1 || echo "No linter configured"
  elif [ -f "pyproject.toml" ]; then
    pylint **/*.py 2>&1 || flake8 . 2>&1 || echo "No linter configured"
  elif [ -f "go.mod" ]; then
    golint ./... 2>&1 || echo "golint not available"
  else
    echo "No linting available for this project"
    return 0
  fi
}
```

### Run All Tests

```bash
run_all_tests() {
  # Detect project type and run all tests
  if [ -f "package.json" ]; then
    npm test 2>&1
  elif [ -f "pytest.ini" ] || [ -f "pyproject.toml" ]; then
    pytest 2>&1
  elif [ -f "go.mod" ]; then
    go test ./... 2>&1
  elif [ -f "Cargo.toml" ]; then
    cargo test 2>&1
  else
    echo "No test framework detected"
    return 1
  fi
}
```

### Run Build

```bash
run_build() {
  # Detect project type and run build
  if [ -f "package.json" ]; then
    npm run build 2>&1 || echo "No build script defined"
  elif [ -f "setup.py" ]; then
    python setup.py build 2>&1
  elif [ -f "go.mod" ]; then
    go build ./... 2>&1
  elif [ -f "Cargo.toml" ]; then
    cargo build 2>&1
  else
    echo "No build process detected"
    return 0
  fi
}
```

### Perform Spec Compliance Check

```bash
perform_spec_compliance_check() {
  local COMPLETED_TASKS=$1

  echo "Checking each task against its acceptance criteria..."
  echo ""

  ISSUES_FOUND=false

  # For each completed task
  echo "$COMPLETED_TASKS" | jq -c '.[]' | while read -r task; do
    TASK_ID=$(echo "$task" | jq -r '.id')
    echo "   Checking $TASK_ID..."

    # Read task file to get acceptance criteria
    TASK_FILE=$(find_task_file "$TASK_ID")
    CRITERIA=$(extract_acceptance_criteria "$TASK_FILE")

    # Verify each criterion
    while IFS= read -r criterion; do
      # Use automated checks where possible
      # For now, assume tests verify criteria
      # In advanced implementation, use pattern matching or AI verification
      echo "     âœ“ $criterion"
    done <<< "$CRITERIA"
  done

  if [ "$ISSUES_FOUND" = true ]; then
    echo "Some acceptance criteria may not be satisfied"
    return 1
  fi

  return 0
}
```

### Perform Code Quality Check

```bash
perform_code_quality_check() {
  echo "Reviewing code for quality issues..."
  echo ""

  # Get all modified files
  MODIFIED_FILES=$(git diff --name-only HEAD~1)

  SUGGESTIONS=()

  # Check each file
  while IFS= read -r file; do
    # Skip non-code files
    [[ "$file" =~ \.(md|json|yaml|yml)$ ]] && continue

    echo "   Reviewing $file..."

    # Check file size (warn if >500 lines)
    LINE_COUNT=$(wc -l < "$file")
    if [ "$LINE_COUNT" -gt 500 ]; then
      SUGGESTIONS+=("$file is large ($LINE_COUNT lines). Consider splitting into smaller modules.")
    fi

    # Check for TODO/FIXME comments
    if grep -q "TODO\|FIXME" "$file"; then
      TODO_COUNT=$(grep -c "TODO\|FIXME" "$file")
      SUGGESTIONS+=("$file has $TODO_COUNT TODO/FIXME comments. Consider addressing them.")
    fi

    # Check for console.log (in JS/TS)
    if [[ "$file" =~ \.(ts|tsx|js|jsx)$ ]] && grep -q "console\\.log" "$file"; then
      SUGGESTIONS+=("$file contains console.log statements. Remove before production.")
    fi

    # Check for commented code
    COMMENT_LINES=$(grep -c "^[[:space:]]*//.*" "$file" 2>/dev/null || echo "0")
    if [ "$COMMENT_LINES" -gt 20 ]; then
      SUGGESTIONS+=("$file has many commented lines ($COMMENT_LINES). Clean up if unnecessary.")
    fi

  done <<< "$MODIFIED_FILES"

  # Report suggestions
  if [ ${#SUGGESTIONS[@]} -gt 0 ]; then
    for suggestion in "${SUGGESTIONS[@]}"; do
      echo "   ğŸ’¡ $suggestion"
    done
    return 1  # Has suggestions but not blocking
  fi

  return 0
}
```

### Generate Detailed Commit Message

```bash
generate_detailed_commit_message() {
  local COMPLETED_TASKS=$1

  # Create conventional commit format with details
  TASK_COUNT=$(echo "$COMPLETED_TASKS" | jq 'length')

  if [ "$TASK_COUNT" -eq 1 ]; then
    # Single task - detailed single commit
    local TASK=$(echo "$COMPLETED_TASKS" | jq -r '.[0]')
    local ID=$(echo "$TASK" | jq -r '.id')
    local MODULE=$(echo "$TASK" | jq -r '.module')
    local DESC=$(echo "$TASK" | jq -r '.description')
    local DURATION=$(echo "$TASK" | jq -r '.duration // "unknown"')
    local TEST_COUNT=$(echo "$TASK" | jq -r '.testResults.unit.passed // 0')
    local COVERAGE=$(echo "$TASK" | jq -r '.testResults.unit.coverage // 0')

    cat <<EOF
feat($MODULE): $DESC

Task: $ID
Duration: $DURATION
Tests: $TEST_COUNT passed, ${COVERAGE}% coverage

Acceptance criteria:
$(echo "$TASK" | jq -r '.acceptanceCriteria[]' | sed 's/^/- /')

Files:
$(git diff --cached --name-only | sed 's/^/- /')
EOF
  else
    # Multiple tasks - batch commit
    MODULES=$(echo "$COMPLETED_TASKS" | jq -r '.[].module' | sort -u | head -1)

    cat <<EOF
feat($MODULES): implement $TASK_COUNT tasks

Tasks completed:
$(echo "$COMPLETED_TASKS" | jq -r '.[] | "- \(.id) (\(.duration // "N/A")): \(.description)"')

All tasks:
- Acceptance criteria satisfied âœ“
- Tests passing âœ“
- Build successful âœ“
EOF
  fi
}

### Update Progress File (Minimal)

```bash
update_progress_txt() {
  local COMPLETED_TASKS=$1
  local COMMIT_SHA=$2

  PROGRESS_FILE="workspace/ai/progress.txt"

  # Append completed tasks to progress file
  echo "$COMPLETED_TASKS" | jq -r '.[] | "\(.status | ascii_upcase): \(.id) (\(.duration // "N/A")) - commit \($commit)"' \
    --arg commit "$COMMIT_SHA" >> "$PROGRESS_FILE"

  # Update stats line
  TOTAL=$(autopilot-cli tasks list --json | jq 'length')
  DONE=$(autopilot-cli tasks list --status completed --json | jq 'length')
  FAILED=$(autopilot-cli tasks list --status failed --json | jq 'length')
  PROGRESS=$((DONE * 100 / TOTAL))

  # Update stats (replace last Stats: line)
  sed -i.bak "/^## Stats/,/^$/c\\
## Stats\\
Total: $TOTAL | Done: $DONE | Failed: $FAILED | Progress: ${PROGRESS}%\\
" "$PROGRESS_FILE"

  echo "âœ“ Progress file updated: $PROGRESS_FILE"
}
```

### Generate PR Title

```bash
generate_pr_title() {
  local COMPLETED_TASKS=$1

  TASK_COUNT=$(echo "$COMPLETED_TASKS" | jq 'length')

  if [ "$TASK_COUNT" -eq 1 ]; then
    # Single task
    echo "$(echo "$COMPLETED_TASKS" | jq -r '.[0].description')"
  else
    # Multiple tasks
    MODULES=$(echo "$COMPLETED_TASKS" | jq -r '.[].module' | sort -u)
    MODULE_COUNT=$(echo "$MODULES" | wc -l)
    echo "Implement $TASK_COUNT features across $MODULE_COUNT modules"
  fi
}
```

### Generate PR Body

```bash
generate_pr_body() {
  local COMPLETED_TASKS=$1
  local SPEC_REVIEW_RESULT=$2
  local QUALITY_REVIEW_RESULT=$3

  cat <<EOF
## Summary

Autopilot implementation of $TASK_COUNT tasks.

## Implemented Tasks

$(echo "$COMPLETED_TASKS" | jq -r '.[] | "- **\(.id)**: \(.description)"')

## Quality Verification

### Quality Gates âœ…
- âœ… Type checking: passed
- âœ… Linting: passed
- âœ… Tests: all passing
- âœ… Build: successful

### Code Review âœ…
- âœ… **Spec Compliance**: All acceptance criteria satisfied
- âœ… **Code Quality**: Meets project standards

$(if [ -n "$QUALITY_REVIEW_RESULT" ]; then
  echo "### Code Quality Notes"
  echo ""
  echo "$QUALITY_REVIEW_RESULT"
fi)

## Test Plan

All tasks include automated tests:
$(echo "$COMPLETED_TASKS" | jq -r '.[] | "- \(.id): \(.testRequirements.unit.pattern // "tests/**/*.test.*")"')

Run tests: \`npm test\` (or project-specific command)

## Deployment Notes

- All changes backward compatible
- No database migrations required
- No environment variable changes

---

ğŸ¤– Generated with [Autopilot](https://github.com/mylukin/autopilot) for Claude Code
EOF
}
```

### Extract Acceptance Criteria

```bash
extract_acceptance_criteria() {
  local TASK_FILE=$1

  # Extract criteria from markdown (after "## Acceptance Criteria" heading)
  sed -n '/## Acceptance Criteria/,/## /p' "$TASK_FILE" | \
    grep -E "^[0-9]+\." | \
    sed 's/^[0-9]*\.\s*//'
}
```

### Find Task File

```bash
find_task_file() {
  local TASK_ID=$1

  # Convert task ID to file path (e.g., auth.login â†’ workspace/ai/tasks/auth/login.md)
  MODULE=$(echo "$TASK_ID" | cut -d. -f1)
  FILENAME=$(echo "$TASK_ID" | cut -d. -f2-).md

  echo "workspace/ai/tasks/$MODULE/$FILENAME"
}
```

### Extract Test Count

```bash
extract_test_count() {
  local TEST_OUTPUT=$1

  # Try common patterns from different test frameworks
  if echo "$TEST_OUTPUT" | grep -q "Tests:.*passed"; then
    # Jest/Vitest pattern: "Tests: 24 passed, 24 total"
    echo "$TEST_OUTPUT" | grep -oP "\d+(?= passed)"
  elif echo "$TEST_OUTPUT" | grep -q "passed in"; then
    # pytest pattern: "24 passed in 1.23s"
    echo "$TEST_OUTPUT" | grep -oP "\d+(?= passed)"
  elif echo "$TEST_OUTPUT" | grep -q "ok.*tests"; then
    # Go pattern: "ok ... 24 tests in 1.234s"
    echo "$TEST_OUTPUT" | grep -oP "\d+(?= tests)"
  else
    echo "unknown"
  fi
}
```

## Error Handling | é”™è¯¯å¤„ç†

| Error | Action |
|-------|--------|
| Quality gate fails | Stop delivery, report failure, don't create commit |
| Spec compliance issues | Note issues but continue (non-blocking) |
| Code quality suggestions | Note suggestions, continue (advisory only) |
| Commit fails | Abort delivery, report error |
| PR creation fails | Continue (manual PR creation fallback) |
| gh CLI not found | Skip PR, show manual instructions |

## Two-Stage Review Explained | ä¸¤é˜¶æ®µå®¡æŸ¥è¯´æ˜

### Stage 1: Spec Compliance Check
**Question**: "Does the implementation satisfy the requirements?"

Checks:
- Each acceptance criterion is met
- Tests verify the criteria
- No requirements missed

**Blocking**: Yes - if criteria not satisfied, implementation is incomplete

### Stage 2: Code Quality Check
**Question**: "Is the code well-written?"

Checks:
- Code style and patterns
- File sizes (not too large)
- No debug code left (console.log, TODO, etc.)
- Commented code cleaned up
- Best practices followed

**Blocking**: No - suggestions are advisory, not mandatory

## Output Examples | è¾“å‡ºç¤ºä¾‹

### Successful Delivery

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ Delivery Complete!

ğŸ“Š Summary:
   Tasks completed: 8
   Commit: a3f2b1c
   Pull Request: https://github.com/user/repo/pull/42

âœ… Quality Gates:
   â€¢ Type checking: âœ“
   â€¢ Linting: âœ“
   â€¢ Tests: âœ“ (87 tests)
   â€¢ Build: âœ“

ğŸ‘€ Code Review:
   â€¢ Spec compliance: âœ“
   â€¢ Code quality: âš ï¸  with suggestions

ğŸ‰ Autopilot workflow complete!
```

### Delivery with Quality Gate Failure

```
âŒ Quality gates failed. Cannot proceed to delivery.

Failed Gates:
   âŒ Tests: 3/87 failed
      â€¢ auth.login.test.ts: should reject invalid password
      â€¢ auth.signup.test.ts: should validate email format
      â€¢ tasks.create.test.ts: should require title

Fix these issues and re-run Phase 5.
```

## Rules | è§„åˆ™

1. **Quality gates are blocking** - Cannot proceed if typecheck/lint/tests/build fail
2. **Spec compliance is blocking** - Must satisfy all acceptance criteria
3. **Code quality is advisory** - Suggestions don't block delivery
4. **Always create commit** - Even if PR creation fails
5. **Include co-author** - Credit Claude in commit message
6. **Two-stage review mandatory** - Both stages must run
7. **Test evidence required** - Must show actual test output, not assertions

## Notes | æ³¨æ„äº‹é¡¹

- Delivery only runs after all Phase 3 tasks complete
- Quality gates ensure production-ready code
- Two-stage review catches both functional and quality issues
- PR creation is optional (requires gh CLI)
- Commit message should be clear and descriptive
- Failed delivery can be retried after fixing issues
