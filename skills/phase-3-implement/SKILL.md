---
name: phase-3-implement
description: Autonomous implementation loop with TDD, fresh agents per task, and self-healing
allowed-tools: [Read, Write, Bash, Task, Grep, Glob]
user-invocable: false
---

# Phase 3: Implementation Loop

## Overview | æ¦‚è¿°

Autonomously implement all tasks using TDD workflow, spawning fresh agents for each task, with automatic error recovery through Phase 4 healing.

ä½¿ç”¨ TDD å·¥ä½œæµè‡ªä¸»å®ç°æ‰€æœ‰ä»»åŠ¡ï¼Œä¸ºæ¯ä¸ªä»»åŠ¡ç”Ÿæˆæ–°çš„ agentï¼Œé€šè¿‡ Phase 4 è‡ªæ„ˆè¿›è¡Œè‡ªåŠ¨é”™è¯¯æ¢å¤ã€‚

## When to Use | ä½•æ—¶ä½¿ç”¨

Invoked by autopilot-orchestrator as Phase 3, after Phase 2 (Breakdown) completes and user approves task plan.

## Input | è¾“å…¥

- Tasks directory: `workspace/ai/tasks/`
- Task index: `workspace/ai/tasks/index.json`
- Language config from index metadata

## Execution | æ‰§è¡Œ

### Step 1: Initialize Implementation Loop

```bash
# Get task count
TASK_COUNT=$(cat workspace/ai/tasks/index.json | jq '.tasks | length')
COMPLETED=0
FAILED=0
HEALED=0

echo "ğŸš€ Starting implementation of $TASK_COUNT tasks..."
echo ""
```

### Step 2: Implementation Loop

```bash
while true; do
  # Get next pending task using CLI
  TASK_JSON=$(autopilot-cli tasks next --json 2>/dev/null)

  if [ -z "$TASK_JSON" ]; then
    echo "âœ… All tasks processed!"
    break
  fi

  # Extract task details
  TASK_ID=$(echo "$TASK_JSON" | jq -r '.id')
  TASK_DESC=$(echo "$TASK_JSON" | jq -r '.description')
  TASK_PRIORITY=$(echo "$TASK_JSON" | jq -r '.priority')
  TASK_EST_MIN=$(echo "$TASK_JSON" | jq -r '.estimatedMinutes')

  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "ğŸ“ Task: $TASK_ID (Priority $TASK_PRIORITY)"
  echo "ğŸ“‹ Description: $TASK_DESC"
  echo "â±ï¸  Estimated: ${TASK_EST_MIN}min"
  echo ""

  # Mark task as started
  autopilot-cli tasks start "$TASK_ID"

  # Record start time
  START_TIME=$(date +%s)

  # Implement the task
  RESULT=$(implement_task "$TASK_ID" "$TASK_JSON")
  STATUS=$?

  # Record end time
  END_TIME=$(date +%s)
  DURATION=$((END_TIME - START_TIME))
  DURATION_MIN=$((DURATION / 60))
  DURATION_SEC=$((DURATION % 60))
  DURATION_STR="${DURATION_MIN}m ${DURATION_SEC}s"

  if [ $STATUS -eq 0 ]; then
    # Task succeeded
    COMPLETED=$((COMPLETED + 1))
    autopilot-cli tasks done "$TASK_ID" --duration "$DURATION_STR"

    echo "âœ… $TASK_ID completed ($COMPLETED/$TASK_COUNT)"
    echo "   Duration: $DURATION_STR"
    echo ""
  else
    # Task failed
    ERROR_MSG=$(echo "$RESULT" | jq -r '.error // "Unknown error"')

    echo "âš ï¸  Error in $TASK_ID"
    echo "   Error: $ERROR_MSG"
    echo ""

    # Attempt auto-healing
    echo "ğŸ”§ Invoking auto-heal..."
    HEAL_RESULT=$(invoke_heal "$TASK_ID" "$ERROR_MSG")
    HEAL_STATUS=$?

    if [ $HEAL_STATUS -eq 0 ]; then
      # Healing succeeded, mark task as done
      COMPLETED=$((COMPLETED + 1))
      HEALED=$((HEALED + 1))
      autopilot-cli tasks done "$TASK_ID" --duration "$DURATION_STR (healed)"

      echo "âœ… Healed successfully!"
      echo ""
    else
      # Healing failed, mark task as failed
      FAILED=$((FAILED + 1))
      autopilot-cli tasks fail "$TASK_ID" --reason "$ERROR_MSG"

      echo "âŒ Failed to heal. Marked as failed."
      echo ""
    fi
  fi

  # Show progress
  TOTAL_PROCESSED=$((COMPLETED + FAILED))
  PROGRESS_PCT=$((TOTAL_PROCESSED * 100 / TASK_COUNT))

  echo "ğŸ“Š Progress: $TOTAL_PROCESSED/$TASK_COUNT tasks ($PROGRESS_PCT%)"
  echo "   âœ… Completed: $COMPLETED"
  echo "   âŒ Failed: $FAILED"
  echo "   ğŸ”§ Auto-healed: $HEALED"
  echo ""
done
```

### Step 3: Implement Single Task Function

```bash
implement_task() {
  local TASK_ID=$1
  local TASK_JSON=$2

  # Extract task details
  local ACCEPTANCE_CRITERIA=$(echo "$TASK_JSON" | jq -r '.acceptanceCriteria[]')
  local TEST_REQUIRED=$(echo "$TASK_JSON" | jq -r '.testRequirements.unit.required')
  local TEST_PATTERN=$(echo "$TASK_JSON" | jq -r '.testRequirements.unit.pattern')

  # Spawn fresh implementer agent
  echo "ğŸ¤– Spawning implementer agent for $TASK_ID..."

  # Use Task tool to invoke implementer agent
  IMPLEMENTER_PROMPT="You are an implementer agent for task: $TASK_ID

Task Details:
$(echo "$TASK_JSON" | jq .)

Your Mission:
1. Implement this task following TDD workflow:
   - RED: Write failing tests first
   - GREEN: Implement minimum code to pass tests
   - REFACTOR: Clean up code while keeping tests passing

2. Satisfy ALL acceptance criteria:
$ACCEPTANCE_CRITERIA

3. Create test files matching pattern: $TEST_PATTERN

4. Ensure tests pass before completing

5. Follow the project's language and framework conventions

CRITICAL: Only implement what's specified in acceptance criteria. No extra features.

Start with tests, then implementation, then verification."

  # Invoke implementer agent via Task tool
  # (In real usage, this would spawn a fresh general-purpose agent)
  # For now, simulate the implementation

  # Actual invocation would be:
  # Use Task tool with:
  #   subagent_type: "general-purpose"
  #   description: "Implement task $TASK_ID"
  #   prompt: "$IMPLEMENTER_PROMPT"

  # Simulated success/failure
  # Return 0 for success, 1 for failure
  return 0
}
```

### Step 4: Invoke Healing Function

```bash
invoke_heal() {
  local TASK_ID=$1
  local ERROR_MSG=$2

  echo "ğŸ”§ Invoking phase-4-heal for error recovery..."

  # Delegate to phase-4-heal skill
  # Use Skill tool or direct invocation

  # Heal function will:
  # 1. WebSearch for error solution
  # 2. Apply fix
  # 3. Re-run tests
  # 4. Return success/failure

  # For now, simulate healing attempt
  # Return 0 for successful heal, 1 for failed heal
  return 1  # Simulate heal failure for now
}
```

### Step 5: Final Summary

```bash
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ¯ Implementation Complete!"
echo ""
echo "ğŸ“Š Final Statistics:"
echo "   Total tasks: $TASK_COUNT"
echo "   âœ… Completed: $COMPLETED"
echo "   âŒ Failed: $FAILED"
echo "   ğŸ”§ Auto-healed: $HEALED"
echo "   Success rate: $((COMPLETED * 100 / TASK_COUNT))%"
echo ""

if [ $FAILED -gt 0 ]; then
  echo "âš ï¸  Some tasks failed. They are marked with status='failed'."
  echo "   Review failed tasks in workspace/ai/tasks/"
  echo ""
fi

echo "â–¶ï¸  Next: Phase 5 (Deliver) - Quality gates and PR creation"
```

### Step 6: Update State

```bash
# Update state to deliver phase
autopilot-cli state update --phase deliver
```

### Step 7: Return Result

```yaml
---PHASE RESULT---
phase: implement
status: complete
completed: {N}
failed: {M}
auto_healed: {K}
success_rate: {X}%
next_phase: deliver
summary: |
  Implemented {N}/{total} tasks successfully.
  Auto-healed {K} errors.
  {M} tasks failed and need manual attention.
  Ready for quality verification and delivery.
---END PHASE RESULT---
```

## Progress Updates | è¿›åº¦æ›´æ–°

Show progress after each task:

```
âœ… auth.signup.ui completed (3/35)
   Duration: 4m 32s
   Tests: 8/8 passed âœ“
   Coverage: 87%
   Files:
     - src/components/SignupForm.tsx (new)
     - tests/components/SignupForm.test.tsx (new)
   Next: auth.signup.validation
```

For errors with healing:

```
âš ï¸  Error in auth.signup.api
    Module 'bcrypt' not found
ğŸ”§ Auto-healing...
   Step 1: WebSearch "npm bcrypt install"
   Step 2: npm install bcrypt@5.1.0
   Step 3: Verify - npm test (âœ… 24/24 passed)
âœ… Healed successfully (1m 12s)
```

## Implementer Agent Template | å®ç°è€… Agent æ¨¡æ¿

When spawning implementer agents, use this prompt template:

```markdown
You are an autonomous implementer agent for a single task.

TASK: {task.id}
DESCRIPTION: {task.description}

ACCEPTANCE CRITERIA:
{criteria-list}

TEST REQUIREMENTS:
- Pattern: {test-pattern}
- Required: {yes/no}
- Min coverage: 80%

## TDD IRON LAW (MANDATORY - NO EXCEPTIONS)

```
NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST
```

**If you wrote code before the test â†’ DELETE it completely. Start over.**

This is non-negotiable. No "reference", no "adaptation", no "keeping it".
DELETE means DELETE.

WORKFLOW (TDD):

1. RED Phase - Write Failing Tests:
   - Create test file: {test-pattern}
   - Write ONE minimal test for FIRST acceptance criterion
   - Run test â†’ MUST show failure (not error, actual test failure)
   - Verify failure message is expected (feature missing, not typo)
   - **If test passes immediately â†’ You're testing existing code, fix the test**
   - **If test errors â†’ Fix error first, then verify it fails correctly**

2. GREEN Phase - Implement Minimum Code:
   - Write SMALLEST amount of code to pass the ONE test
   - No extra features beyond what the test requires
   - No premature optimization
   - No refactoring of other code
   - Run tests â†’ they MUST pass
   - **If test still fails â†’ Fix code, NOT test**

3. REFACTOR Phase - Clean Code (ONLY after GREEN):
   - Improve naming, structure
   - Remove duplication
   - Apply design patterns if appropriate
   - Run tests after EACH change â†’ must stay passing
   - **If tests fail during refactor â†’ Revert change immediately**

4. REPEAT - Next Test:
   - Go back to RED for next acceptance criterion
   - One test at a time, one feature at a time
   - Complete RED-GREEN-REFACTOR cycle for each

5. VERIFY - Final Check:
   - All tests pass âœ“
   - Coverage >80% âœ“
   - All acceptance criteria satisfied âœ“
   - No linting errors âœ“
   - Output pristine (no warnings, no console.log) âœ“

## VERIFICATION CHECKLIST (MANDATORY)

Before marking task complete, verify EVERY item:

- [ ] Every new function/method has a test
- [ ] Watched each test fail BEFORE implementing (saw RED)
- [ ] Each test failed for expected reason (feature missing, not typo)
- [ ] Wrote minimal code to pass each test (no over-engineering)
- [ ] All tests pass (run full test suite)
- [ ] No test was written after the code (all tests-first)
- [ ] Tests use real code, not mocks (unless unavoidable)
- [ ] Edge cases and errors covered
- [ ] No production code exists without a corresponding test

**Cannot check all boxes? â†’ Start over with TDD. No exceptions.**

## RED FLAGS - STOP IMMEDIATELY

If you catch yourself:
- Writing code before test
- Test passes on first run (didn't see it fail)
- Adding multiple tests before any implementation
- Implementing features not required by current test
- "I'll add tests after to verify it works"
- "This is too simple to test"
- "I already manually tested it"
- Keeping code written before tests "as reference"

**ALL of these mean: DELETE CODE. Start over with TDD.**

CONSTRAINTS:
- Only implement what's specified in acceptance criteria
- Follow TDD Iron Law strictly (tests ALWAYS first, no exceptions)
- Use project's language/framework conventions
- Keep code clean and simple
- One test â†’ One minimal implementation â†’ Refactor â†’ Repeat

OUTPUT:
When done, report:
- Files created/modified
- Test results (pass count, coverage %)
- Duration
- Any issues encountered
```

## Error Handling | é”™è¯¯å¤„ç†

| Error | Action |
|-------|--------|
| No tasks found | Prompt to run Phase 2 |
| Task implementation fails | Invoke Phase 4 (heal) |
| Healing fails (max 3 attempts) | Mark task as failed, continue |
| All tasks fail | Continue to Phase 5, report failures |
| User interrupts | Save state, allow resume |

## Example Flow | ç¤ºä¾‹æµç¨‹

```
ğŸš€ Starting implementation of 35 tasks...

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ Task: setup.scaffold (Priority 1)
ğŸ“‹ Description: Initialize project structure
â±ï¸  Estimated: 15min

ğŸ¤– Spawning implementer agent...
âœ… setup.scaffold completed (1/35)
   Duration: 3m 47s

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ Task: auth.signup.ui (Priority 5)
ğŸ“‹ Description: Create signup form component
â±ï¸  Estimated: 20min

ğŸ¤– Spawning implementer agent...
âš ï¸  Error: Module 'react-hook-form' not found
ğŸ”§ Invoking auto-heal...
âœ… Healed successfully! (1m 23s)
âœ… auth.signup.ui completed (5/35)
   Duration: 6m 12s (healed)

ğŸ“Š Progress: 5/35 tasks (14%)
   âœ… Completed: 5
   âŒ Failed: 0
   ğŸ”§ Auto-healed: 1

[... continues for all 35 tasks ...]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ Implementation Complete!

ğŸ“Š Final Statistics:
   Total tasks: 35
   âœ… Completed: 33
   âŒ Failed: 2
   ğŸ”§ Auto-healed: 4
   Success rate: 94%

â–¶ï¸  Next: Phase 5 (Deliver)
```

## Rules | è§„åˆ™

1. **Fresh agent per task** - Prevent context pollution
2. **TDD workflow mandatory** - Tests before implementation
3. **Auto-heal on first error** - Try to fix automatically
4. **Mark failed after heal attempts** - Continue to next task
5. **Show progress regularly** - After each task and every 3 tasks
6. **Never skip tasks** - Process in priority order
7. **Save state continuously** - Can resume anytime

## Notes | æ³¨æ„äº‹é¡¹

- Implementation quality depends on clear acceptance criteria
- Fresh agents ensure no context bleed between tasks
- Auto-healing uses Phase 4 (WebSearch-powered)
- Failed tasks can be manually fixed and re-run later
- Progress is persisted in task files and state.json
